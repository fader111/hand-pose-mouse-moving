{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mediapipe opencv-python==4.5.5.64\n",
    "#!pip install pyautogui\n",
    "# source idea from https://www.youtube.com/watch?v=vQZ4IvB07ec&t=347s\n",
    "# source https://google.github.io/mediapipe/solutions/hands\n",
    "# полезно по оформлению https://habr.com/ru/post/485318/\n",
    "# мышь https://myrusakov.ru/python-gui-automation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import keyboard\n",
    "import pyautogui\n",
    "from filterpy.kalman import KalmanFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.size()  # Size(width=3840, height=2160)\n",
    "pyautogui.PAUSE = 1\n",
    "pyautogui.FAILSAFE = True # security"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands \n",
    "<img src=https://i.imgur.com/qpRACer.png />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные фишечки\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0, 255)\n",
    "white = (255, 255, 255)\n",
    "# cv2.putText(image, text, org, font, fontScale, color[,\n",
    "#               thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "\n",
    "def text(image, text, pos=(10, 30), fontScale=1, color=red, thickness=2):\n",
    "    cv2.putText(image, text, pos, cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=fontScale, color=color, thickness=thickness)\n",
    "\n",
    "\n",
    "def dist_betw_points(pt1, pt2):\n",
    "    \"\"\" calc distance betw 2 points\"\"\"\n",
    "    return math.sqrt((pt2[0]-pt1[0])*(pt2[0]-pt1[0]) +\n",
    "                     (pt2[1]-pt1[1])*(pt2[1]-pt1[1]) + (pt2[2]-pt1[2])*(pt2[2]-pt1[2]))\n",
    "\n",
    "\n",
    "def finger_connect_evt(pt1_tip, pt1_pip, pt2_tip, pt2_prev):\n",
    "    \"\"\" connect finger event calc as a ratio of 2 distances - \n",
    "        first is the distance beetween finger ends, second - is \n",
    "        between pre-end finger points\n",
    "    \"\"\"\n",
    "    # TODO!!\n",
    "    pass\n",
    "\n",
    "\n",
    "def pos_perst(hand, perst, coord):  # нужно ли это??? хз\n",
    "    return hand.landmark[perst].coord\n",
    "\n",
    "\n",
    "def move_pt(pt, pt_step, mult=1):\n",
    "    return np.array([(pt[0]-pt_step[0])*mult, (pt[1]-pt_step[1])*mult], dtype = np.float32)\n",
    "\n",
    "\n",
    "def kalman_init():\n",
    "    # инициализация фильтра\n",
    "    dt = 1.0/30  # time step\n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    kf.x = np.array([0, 0, 0, 0])  # initial state (x, y, vx, vy)\n",
    "    kf.F = np.array([[1, 0, dt, 0],\n",
    "                    [0, 1, 0, dt],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0 ,1]])  # state transition matrix\n",
    "\n",
    "    kf.H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]]) # measurement function\n",
    "    kf.P *= 1000.0 # initial state covariance\n",
    "    k01 = 2.9\n",
    "    k001 = 2.1\n",
    "    kf.R = np.array([[k01, 0],[0, k01]]) # measurement noise covariance\n",
    "    kf.Q = np.array([[k001, 0, k01, 0], [0, k001, 0, k01], [k01, 0, 1, 0], [0, k01, 0, 1]]) # process noise covariance\n",
    "    return kf\n",
    "\n",
    "class Median:\n",
    "    def __init__(self, x, y, buffer_size =10):\n",
    "        self.buffer = [[x]*buffer_size, [y]*buffer_size]\n",
    "    def __call__(self, x,y):\n",
    "        self.buffer = [self.buffer[0][1:], self.buffer[1][1:]]\n",
    "        self.buffer[0].append(x)\n",
    "        self.buffer[1].append(y)\n",
    "        return sum(self.buffer[0]) / len(self.buffer[0]),  sum(self.buffer[1]) / len(self.buffer[1]) \n",
    "\n",
    "# def median_x(f):\n",
    "#     # Creating buffer\n",
    "#     if not hasattr(median_x, \"buffer\"):\n",
    "#         median_x.buffer = [f] * 10\n",
    "#     median_x.buffer = median_x.buffer[1:]\n",
    "#     median_x.buffer.append(f)\n",
    "#     return sum(median_x.buffer) / len(median_x.buffer)\n",
    "\n",
    "# def median_y(f):\n",
    "#     # Creating buffer\n",
    "#     if not hasattr(median_y, \"buffer\"):\n",
    "#         median_y.buffer = [f] * 10\n",
    "#     median_y.buffer = median_y.buffer[1:]\n",
    "#     median_y.buffer.append(f)\n",
    "#     return sum(median_y.buffer) / len(median_y.buffer)\n",
    "\n",
    "\n",
    "def averaging_tpis_position(pt1_tip, pt2_tip):\n",
    "    x= (pt1_tip[0] + pt2_tip[0])/2\n",
    "    y= (pt1_tip[1] + pt2_tip[1])/2\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!\n",
    "# сделать фильтр кальмана для сглаживания трека от которого будет мышка двигаться\n",
    "# делать что-то для корректной работы, если есть вторая рука в кадре\n",
    "#       например, работать с двумя руками, и брать в работу только то,\n",
    "\n",
    "# DONE делать привязку к мышке\n",
    "# DONE в первом приближении, возможно требует улучшений после привязки мыши.\n",
    "#       DONE при фронтальном ракурсе руки соотношение длин, по которому принимается решение для\n",
    "#       передвижения курсора оказывается ниже порога.\n",
    "\n",
    "#       делать масштаб кисти для вычисления порога в зависимости от удаления от камеры.\n",
    "#       тупое измерение расстояния между кончиками пальцев часто не дает эффекта, т.к.\n",
    "#       эти кончики оказываются в разных местах в зависимости от ракурса.\n",
    "#       поэтомуесть идея оценить взимное расоложение пальцев с использованием других точек\n",
    "#       пальца.\n",
    "# DONE разбираться как влияет z координата пока вроде без нее работает лучше чем с ней.\n",
    "# DONE установить лимит на одну руку\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Malfunc with front view \n",
    "<img src=\"pics/front_palm_front_malfunc.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "use_kalman = True \n",
    "\n",
    "cam = 2  # 0,1 - какая первая подключилась\n",
    "cap = cv2.VideoCapture(cam)\n",
    "while not cap.isOpened(): # await camera \n",
    "    pass\n",
    "ret, frame = cap.read()\n",
    "image_hight, image_width = frame.shape[:2]\n",
    "index_tip = mp_hands.HandLandmark.INDEX_FINGER_TIP      # указательный конец\n",
    "# index_dip = mp_hands.HandLandmark.INDEX_FINGER_DIP   # указательный 2 точка\n",
    "index_pip = mp_hands.HandLandmark.INDEX_FINGER_PIP     # указательный 2 точка\n",
    "thumb_tip = mp_hands.HandLandmark.THUMB_TIP             # большой конец\n",
    "# thumb_ip = mp_hands.HandLandmark.THUMB_IP           # большой вторая точка\n",
    "thumb_mcp = mp_hands.HandLandmark.THUMB_MCP            # большой вторая точка\n",
    "\n",
    "dist_ratio_thresh = 3.2\n",
    "dist_ends, dist_prevs = 1, 1\n",
    "dist_ratio = 1\n",
    "pt1_tip = (100, 100)\n",
    "pt1_pip = (100, 100)\n",
    "pt2_tip = (100, 100)\n",
    "pt2_mcp = (100, 100)\n",
    "pt_curs_driver_prev = (100, 100)   # предыдущая позиция курсора для отслеживания относительного перемещения\n",
    "x,y = (0, 0)             # дискрет перемещения\n",
    "contact = False         # признак того что пальцы соединились\n",
    "\n",
    "# инициализация фильтра калмана, медианнного фильтра\n",
    "kf = kalman_init()\n",
    "median = Median(x,y)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.8, max_num_hands=2) as hands:\n",
    "    while cap.isOpened():\n",
    "        t0 = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        # Detection\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # print(f\"res {results}\")\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                # только правая рука ( картинка зеркальная )\n",
    "                if results.multi_handedness[num].classification[0].label == \"Left\":\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image, hand, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    pt1_tip = (hand.landmark[index_tip].x,\n",
    "                            hand.landmark[index_tip].y, 0)\n",
    "                    pt1_pip = (hand.landmark[index_pip].x,\n",
    "                                hand.landmark[index_pip].y, 0)\n",
    "\n",
    "                    pt2_tip = (hand.landmark[thumb_tip].x,\n",
    "                            hand.landmark[thumb_tip].y, 0)\n",
    "                    pt2_mcp = (hand.landmark[thumb_mcp].x,\n",
    "                                hand.landmark[thumb_mcp].y, 0)\n",
    "\n",
    "                    dist_ends = dist_betw_points(pt1_tip, pt2_tip)\n",
    "                    dist_ends = dist_ends if dist_ends != 0 else 0.01  # prevent div by zero\n",
    "\n",
    "                    dist_prevs = dist_betw_points(pt1_pip, pt2_mcp)\n",
    "\n",
    "        contact = True if dist_ratio > dist_ratio_thresh else False\n",
    "\n",
    "        # вычислить соотношение дистанций соответствующих точек пальцев\n",
    "        dist_ratio = dist_prevs/dist_ends\n",
    "        # вычислить перемещение мыши - сразу умножим движ на mult\n",
    "        # пробуем сначала усреднить положение концов указательного и большого \n",
    "        pt_curs_driver = averaging_tpis_position(pt1_tip, pt2_tip)\n",
    "\n",
    "        dx,dy = move_pt(pt_curs_driver, pt_curs_driver_prev, mult=15000)\n",
    "        \n",
    "        if contact:\n",
    "            if use_kalman:\n",
    "                z = np.array([dx, dy]) # measurement (x, y)\n",
    "                # kf.predict()\n",
    "                # x, y, _, _ = kf.x\n",
    "                kf.update(z)\n",
    "                # Экспоненциальное сглаживание !!! тут продолжать!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                alpha = 0.51\n",
    "                # prev_x = filtered_x\n",
    "                # exp_x = alpha * x + (1 - alpha) * pt_curs_driver_prev[0]\n",
    "                # exp_y = alpha * y + (1 - alpha) * pt_curs_driver_prev[1]\n",
    "\n",
    "                dx,dy = median(dx,dy)\n",
    "\n",
    "                # if dx>5:\n",
    "                #     dx=5\n",
    "                # if dx<-5:\n",
    "                #     dx=-5\n",
    "                # if dy>5:\n",
    "                #     dy=5\n",
    "                # if dy<-5:\n",
    "                #     dy=-5\n",
    "                \n",
    "                coef = 1\n",
    "                # dx = coef*math.exp(dx) if dx>0 else coef*-math.exp(-dx)\n",
    "                # dy = coef*math.exp(dy) if dy>0 else coef*-math.exp(-dy)\n",
    "                # medi_y = median_y(y)\n",
    "            # pyautogui.moveRel(-x, -y, _pause=False)\n",
    "            try:\n",
    "                pyautogui.moveRel(-dx, -dy, _pause=False)\n",
    "            except Exception as inst:\n",
    "                print(inst)\n",
    "                \n",
    "        \n",
    "        # переписать значение мыши предыдущего цикла\n",
    "        # привязать мышь к концу указательного пальца\n",
    "        pt_curs_driver_prev = pt_curs_driver\n",
    "\n",
    "        time_spend = time.time() - t0\n",
    "\n",
    "        color = green if contact else False\n",
    "        text(image, f'{dist_ends:.2f} {dist_prevs:.2f} {dist_ratio:.2f}', color=color)\n",
    "        text(image, f'{pt1_tip[0]:.2f} {pt1_tip[1]:.2f} : {dx:.0f} {dy:.0f} ',\n",
    "                    pos=(300, 30), color=white, thickness=1)\n",
    "        text(image, f'{pyautogui.position().x} {pyautogui.position().y}',\n",
    "                    pos=(300, 60), color=white, thickness=1)\n",
    "        text(image, f'ts {time_spend:.3}', pos=(10, 60), color=white) # time spend indicator 0.02 for 2 hands\n",
    "        # assert x*100<10, x\n",
    "\n",
    "        image = cv2.resize(image, (image.shape[1]*3, image.shape[0]*3))  # optional\n",
    "        cv2.imshow('hands', image)\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23400/1012363586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# mp_hands.HAND_CONNECTIONS??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# mp_drawing.DrawingSpec??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_handedness\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" {mh.classification[0].label}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# print(f\" {mh.classification}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# results.multi_hand_landmarks\n",
    "# mp_hands.HAND_CONNECTIONS??\n",
    "# mp_drawing.DrawingSpec??\n",
    "for mh in results.multi_handedness:\n",
    "    print(f\" {mh.classification[0].label}\")\n",
    "    # print(f\" {mh.classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.multi_hand_landmarks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 0\n",
    "for i in range(0): # 5\n",
    "    # pyautogui.moveRel(100, 0, duration=duration)\n",
    "    pyautogui.moveRel(100, 0)\n",
    "    pyautogui.moveRel(0, 100, duration=duration)\n",
    "    pyautogui.moveRel(-100, 0, duration=duration)\n",
    "    pyautogui.moveRel(0, -100, duration=duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import time\n",
    "\n",
    "while False:# True:\n",
    "    if keyboard.is_pressed('ctrl'):\n",
    "        time.sleep(0.1)\n",
    "        print(f\"ctrl pressed\")\n",
    "        keyboard.release(\"ctrl\")\n",
    "        # keyboard.send(\"ctrl\")\n",
    "        # keyboard.unhook_all()\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "while 1:\n",
    "   a= pyautogui.position()\n",
    "   b= pyautogui.position()\n",
    "   if a!=b:\n",
    "      print(pyautogui.position().x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
